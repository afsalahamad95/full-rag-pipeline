# -*- coding: utf-8 -*-
"""RAG application.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LAaNFQ8ojnnKLFTJE1Po4u-cmdt0TkZn

## install dependencies
"""

# !pip install langchain
# !pip install langchain_community
# !pip install -qU chromadb langchain-chroma
# !pip install groq

"""## setup environment"""

from dotenv import load_dotenv
from langchain_core.documents import (
    Document,
)  # common format for data retrieval and processing workflows
from langchain_community.document_loaders import (
    TextLoader,
    DirectoryLoader,
)  # load the entire directory, and filter out files with pattern matching
from langchain_community.embeddings import HuggingFaceEmbeddings
import os
from langchain_chroma import Chroma

load_dotenv()
groqAPIKEY = os.getenv("GROQ_API_KEY")

kb_dir_path = "/content/drive/MyDrive"
dir_loader = DirectoryLoader(
    kb_dir_path,
    glob="*.txt",
    loader_cls=TextLoader,
    loader_kwargs={"encoding": "utf-8"},
    show_progress=True,
)

docs = dir_loader.load()

from langchain_community.embeddings import HuggingFaceEmbeddings

# define the embedding method
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# embedding the documents to store them in our vector DB
vector_store = Chroma(collection_name="rag", embedding_function=embeddings)
vector_store.add_documents(documents=docs)

results = vector_store.similarity_search(
    query="what are the traits of a good corpus?", k=1
)
for doc in results:
    print(doc)

# retrieve data via a retriever
retriever = vector_store.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 1, "fetch_k": 2, "lambda_mult": 0.5},
)

"""Query Processing Phase"""

user_query = input("Ask me anything, I'll answer if I know something about it.")
results = retriever.invoke(user_query)

context = ""
for i, res in enumerate(results):
    print(f"doc {i} = {res}")
    context += res.page_content
    context += "\n---\n"

"""Generation Phase"""

from groq import Groq
from google.colab import userdata

apikey = userdata.get("GROQ_API_KEY")
client = Groq(api_key=apikey)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant. Respond only from the given context, if you don't know, respond saying you don't know about the query.",
        },
        {"role": "user", "content": "Find the context below:"},
        {"role": "user", "content": context},
        {"role": "user", "content": user_query},
    ],
    model="groq/compound",
    temperature=0.5,
    top_p=1,
)

print(chat_completion.choices[0].message.content)
